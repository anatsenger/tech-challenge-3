{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8380484",
   "metadata": {},
   "source": [
    "# Tech Chalenge 3 - FIAP\n",
    "\n",
    "A proposta aqui é fazer um Fine Tunning, como demostrado em aula. Usando o um  `foundation model` de base e o dataset `The AmazonTitles-1.3MM` para o tunning.\n",
    "\n",
    "Para isso é necessário:\n",
    "1. Preparação do ambiente\n",
    "2. Preparar a base/dataset\n",
    "3. Carregar o Foundation Model\n",
    "4. Fazer o Fine Tunning\n",
    "5. Conferir as Resposta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad163ca",
   "metadata": {},
   "source": [
    "## 1. Preparação do ambiente\n",
    "\n",
    "### 1.1. Instalando dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4464176f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Cloning https://github.com/unslothai/unsloth.git to c:\\users\\ana\\appdata\\local\\temp\\pip-install-c8x3fj1a\\unsloth_b94b640750f44beebe584a4fac86e589\n",
      "  Resolved https://github.com/unslothai/unsloth.git to commit 67ea5e422d65b9afa15748e56d2b1495e5ac06e5\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting unsloth_zoo>=2025.9.14 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading unsloth_zoo-2025.9.14-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.0)\n",
      "Collecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading tyro-0.9.32-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting datasets!=4.0.*,!=4.1.0,>=3.4.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Collecting tqdm (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (7.0.0)\n",
      "Collecting wheel>=0.42.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.6)\n",
      "Collecting protobuf (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting hf_transfer (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting bitsandbytes>=0.45.5 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading bitsandbytes-0.48.1-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Collecting torch<3,>=2.3 (from bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading torch-2.8.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting filelock (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
      "Collecting xxhash (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.6)\n",
      "Collecting regex!=2019.12.17 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading regex-2025.9.18-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,<=4.56.2,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting torchao (from unsloth_zoo>=2025.9.14->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading torchao-0.13.0-1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting triton_windows (from unsloth_zoo>=2025.9.14->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading triton_windows-3.4.0.post20-cp313-cp313-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting accelerate>=0.34.1 (from unsloth_zoo>=2025.9.14->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.23.0,>=0.7.9 (from unsloth_zoo>=2025.9.14->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading trl-0.23.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth_zoo>=2025.9.14->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.9.14->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from unsloth_zoo>=2025.9.14->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.9.14->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading msgspec-0.19.0-cp313-cp313-win_amd64.whl.metadata (7.1 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=11.1.0 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading aiohttp-3.12.15-cp313-cp313-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.4.26)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n",
      "Collecting sympy>=1.13.3 (from torch<3,>=2.3->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch<3,>=2.3->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch<3,>=2.3->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (80.8.0)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading multidict-6.6.4-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl.metadata (76 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch<3,>=2.3->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
      "Downloading bitsandbytes-0.48.1-py3-none-win_amd64.whl (59.5 MB)\n",
      "   ---------------------------------------- 0.0/59.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 3.4/59.5 MB 19.5 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 10.0/59.5 MB 26.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 18.4/59.5 MB 31.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 26.7/59.5 MB 34.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 36.4/59.5 MB 36.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 45.1/59.5 MB 37.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 55.1/59.5 MB 39.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 59.5/59.5 MB 37.8 MB/s eta 0:00:00\n",
      "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 0.0/564.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 564.3/564.3 kB 28.4 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 37.7 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 50.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 46.2 MB/s eta 0:00:00\n",
      "Downloading unsloth_zoo-2025.9.14-py3-none-any.whl (256 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading hf_transfer-0.1.9-cp38-abi3-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 38.2 MB/s eta 0:00:00\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading tyro-0.9.32-py3-none-any.whl (132 kB)\n",
      "Downloading accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "   ---------------------------------------- 0.0/26.1 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 11.8/26.1 MB 55.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.3/26.1 MB 52.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.1/26.1 MB 48.7 MB/s eta 0:00:00\n",
      "Downloading regex-2025.9.18-cp313-cp313-win_amd64.whl (275 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 42.8 MB/s eta 0:00:00\n",
      "Downloading torch-2.8.0-cp313-cp313-win_amd64.whl (241.3 MB)\n",
      "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 8.9/241.3 MB 42.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 18.9/241.3 MB 45.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 30.4/241.3 MB 48.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 41.7/241.3 MB 50.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 51.9/241.3 MB 50.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 64.5/241.3 MB 51.8 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 75.5/241.3 MB 52.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 85.2/241.3 MB 51.3 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 97.8/241.3 MB 52.4 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 109.3/241.3 MB 52.5 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 120.1/241.3 MB 52.6 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 132.1/241.3 MB 53.0 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 143.4/241.3 MB 53.2 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 155.7/241.3 MB 53.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 167.0/241.3 MB 53.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 176.4/241.3 MB 53.0 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 185.9/241.3 MB 52.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 198.4/241.3 MB 53.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 209.7/241.3 MB 53.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 221.0/241.3 MB 53.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 233.8/241.3 MB 53.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 53.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 53.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 241.3/241.3 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading trl-0.23.0-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 0.0/564.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 564.7/564.7 kB 27.3 MB/s eta 0:00:00\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading msgspec-0.19.0-cp313-cp313-win_amd64.whl (187 kB)\n",
      "Downloading torchao-0.13.0-1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 41.1 MB/s eta 0:00:00\n",
      "Downloading triton_windows-3.4.0.post20-cp313-cp313-win_amd64.whl (42.7 MB)\n",
      "   ---------------------------------------- 0.0/42.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 13.4/42.7 MB 62.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 24.1/42.7 MB 56.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 35.9/42.7 MB 55.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  42.5/42.7 MB 50.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 42.7/42.7 MB 47.2 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Downloading aiohttp-3.12.15-cp313-cp313-win_amd64.whl (449 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.3/6.3 MB 36.1 MB/s eta 0:00:00\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 49.2 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 28.2 MB/s eta 0:00:00\n",
      "Downloading multidict-6.6.4-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Building wheels for collected packages: unsloth\n",
      "  Building wheel for unsloth (pyproject.toml): started\n",
      "  Building wheel for unsloth (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for unsloth: filename=unsloth-2025.9.11-py3-none-any.whl size=320173 sha256=eda85bd114f08a53e11f3627f93f8dde936eb475b212cb343c4c07b86f220d37\n",
      "  Stored in directory: C:\\Users\\Ana\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-g_ni4ot9\\wheels\\d5\\36\\1d\\4e65996c5b80c84a5ac1b0ba10718bdc155f8dd04352746a8f\n",
      "Successfully built unsloth\n",
      "Installing collected packages: torchao, mpmath, xxhash, wheel, unsloth, typing-extensions, triton_windows, tqdm, sympy, shtab, sentencepiece, safetensors, regex, pyarrow, protobuf, propcache, networkx, multidict, msgspec, mdurl, hf_transfer, fsspec, frozenlist, filelock, docstring-parser, dill, aiohappyeyeballs, yarl, typeguard, torch, multiprocess, markdown-it-py, huggingface_hub, aiosignal, tokenizers, rich, cut_cross_entropy, bitsandbytes, aiohttp, accelerate, tyro, transformers, peft, datasets, trl, unsloth_zoo\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.13.2\n",
      "    Uninstalling typing_extensions-4.13.2:\n",
      "      Successfully uninstalled typing_extensions-4.13.2\n",
      "Successfully installed accelerate-1.10.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 bitsandbytes-0.48.1 cut_cross_entropy-25.1.1 datasets-4.1.1 dill-0.4.0 docstring-parser-0.17.0 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.9.0 hf_transfer-0.1.9 huggingface_hub-0.35.3 markdown-it-py-4.0.0 mdurl-0.1.2 mpmath-1.3.0 msgspec-0.19.0 multidict-6.6.4 multiprocess-0.70.16 networkx-3.5 peft-0.17.1 propcache-0.3.2 protobuf-6.32.1 pyarrow-21.0.0 regex-2025.9.18 rich-14.1.0 safetensors-0.6.2 sentencepiece-0.2.1 shtab-1.7.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.8.0 torchao-0.13.0 tqdm-4.67.1 transformers-4.56.2 triton_windows-3.4.0.post20 trl-0.23.0 typeguard-4.4.4 typing-extensions-4.15.0 tyro-0.9.32 unsloth-2025.9.11 unsloth_zoo-2025.9.14 wheel-0.45.1 xxhash-3.6.0 yarl-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git 'C:\\Users\\Ana\\AppData\\Local\\Temp\\pip-install-c8x3fj1a\\unsloth_b94b640750f44beebe584a4fac86e589'\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xformers\n",
      "  Downloading xformers-0.0.32.post2-cp39-abi3-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting trl<0.9.0\n",
      "  Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.48.1)\n",
      "Downloading xformers-0.0.32.post2-cp39-abi3-win_amd64.whl (100.2 MB)\n",
      "   ---------------------------------------- 0.0/100.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 4.5/100.2 MB 28.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 11.3/100.2 MB 31.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 15.7/100.2 MB 28.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 22.3/100.2 MB 28.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 30.4/100.2 MB 31.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 41.4/100.2 MB 34.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 52.2/100.2 MB 37.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 62.1/100.2 MB 39.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 73.1/100.2 MB 40.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 80.0/100.2 MB 41.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 92.8/100.2 MB 41.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  100.1/100.2 MB 42.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 100.2/100.2 MB 40.2 MB/s eta 0:00:00\n",
      "Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
      "Installing collected packages: xformers, trl\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.23.0\n",
      "    Uninstalling trl-0.23.0:\n",
      "      Successfully uninstalled trl-0.23.0\n",
      "Successfully installed trl-0.8.6 xformers-0.0.32.post2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.56.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ana\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c5021c",
   "metadata": {},
   "source": [
    "### 1.12. Importantando dependências necessárias para o processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c0505b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unsloth currently only works on NVIDIA GPUs and Intel GPUs.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel, is_bfloat16_supported\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ana\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\unsloth\\__init__.py:87\u001b[39m\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth currently only works on NVIDIA GPUs and Intel GPUs.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m DEVICE_TYPE : \u001b[38;5;28mstr\u001b[39m = \u001b[43mget_device_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;129m@functools\u001b[39m.cache\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_device_count\u001b[39m():\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m DEVICE_TYPE \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhip\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ana\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\unsloth\\__init__.py:85\u001b[39m, in \u001b[36mget_device_type\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch, \u001b[33m\"\u001b[39m\u001b[33mxpu\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m torch.xpu.is_available():\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mxpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsloth currently only works on NVIDIA GPUs and Intel GPUs.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Unsloth currently only works on NVIDIA GPUs and Intel GPUs."
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import torch\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011aacd1",
   "metadata": {},
   "source": [
    "### 1.3. Montando o drive pra acessar a base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c8e3f9",
   "metadata": {},
   "source": [
    "### 1.4 Setando variáveis de ambiente\n",
    "Temos diversos conjuntos de variáveis que precisaremos usar durante o processamento. Optamos por deixar todas aqui na seção inicial para facilitar qualquer ajuste global nos parâmtros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMAZON_TITLES_PATH = \"/content/drive/MyDrive/Estudo/trn.json\"\n",
    "AMAZON_TITLES_TRATADOS_PATH = \"/content/drive/MyDrive/Estudo/trn_tratado.json\"\n",
    "\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "DTYPE = None\n",
    "LOAD_IN_4BIT = True\n",
    "_4BIT_MODELS = [\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "    \"unsloth/llama-3-70b-bnb-4bit\",\n",
    "    \"unsloth/Phi-3-mini-4k-instruct\",\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05ab48",
   "metadata": {},
   "source": [
    "## 2. Leitura, Limpeza e Tratamento da base\n",
    "\n",
    "> Essa seção precisa ser executada apenas UMA vez. Com os dados tratados, se você já executou ela alguma vez, pode pular direto para a Seção 3.\n",
    "\n",
    "Lendo o arquivo `trn.json`do `dataset\n",
    "AmazonTitles-1.3MM`.  \n",
    "\n",
    "Aqui desprezei todos os registros onde o `content` estava vázio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = []\n",
    "\n",
    "with open(AMAZON_TITLES_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        j = json.loads(line)\n",
    "        if j.get('content'):\n",
    "          processed_data.append({\n",
    "              'title': j.get('title', ''),\n",
    "              'content': j.get('content', '')\n",
    "          })\n",
    "\n",
    "print(f\"Quantidade de linhas completas: {len(processed_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144bcf1",
   "metadata": {},
   "source": [
    "Mostrando os primeiros registros carregados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba24bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in processed_data[:30]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af6ee6",
   "metadata": {},
   "source": [
    "Salvando no Drive pra não precisar repetir isso toda vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dcd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(AMAZON_TITLES_TRATADOS_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump(processed_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"Dados tratados salvos em: {AMAZON_TITLES_TRATADOS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0403f8",
   "metadata": {},
   "source": [
    "## 3. Carregando e testando um Foundation Model\n",
    "\n",
    "Estamos usando um modelo que roda localmente, nesse caso o llama 3 com 8bi de parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af71988",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n",
    "    max_seq_length = MAX_SEQ_LENGTH,\n",
    "    dtype = DTYPE,\n",
    "    load_in_4bit = LOAD_IN_4BIT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Describe the product of [INPUT]\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c846a8f5",
   "metadata": {},
   "source": [
    "### 3.1 Testando o modelo antes do Tunning\n",
    "\n",
    "Aqui vamos pedir pra ele descrever o `Girls Ballet Tutu Neon Pink` e ver o que volta!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439df89",
   "metadata": {},
   "source": [
    "Algumas respostas que o modelo **sem Fine Tunning**, para o `Girls Ballet Tutu Neon Pink` deu:\n",
    "\n",
    "> A tutu is a type of skirt that is worn by ballet dancers. It is typically made of tulle or netting and is attached to a bodice or leotard. The tutu is usually white or pink in color and is often adorned with ribbons or flowers. Tutus are usually worn by female ballet dancers, but they can also be worn by male ballet dancers in some cases. The tutu is an important part of the ballet costume and is often seen as a symbol of femininity and grace.\n",
    "\n",
    "> A girls neon pink tutu.\n",
    "\n",
    "> A ballet tutu is a product of the ballet dance. It is a skirt that is worn by ballerinas and is usually made of tulle. It is typically white, but can be any color. A ballet tutu is a product of the ballet dance. It is a skirt that is worn by ballerinas and is usually made of tulle. It is typically white, but can be any color.\n",
    "\n",
    "> The product of Girls Ballet Tutu Neon Pink is a beautiful ballet tutu in a vibrant pink color. This tutu is perfect for young dancers who want to look their best on stage. The tutu is made of high-quality materials and features a comfortable fit. It is available in a variety of sizes to fit all dancers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4aacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt.format(\n",
    "        \"Autumn Story Brambly Hedge\",\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66d01d",
   "metadata": {},
   "source": [
    "Algumas respostas que o modelo **sem Fine Tunning**, para o `Autumn Story Brambly Hedge` deu:\n",
    "\n",
    "> The product of Autumn Story Brambly Hedge is a book that was published in 1980. It is a children's book that tells the story of a group of mice who live in a village called Brambly Hedge. The book is written by Joyce Lankester Brisley and illustrated by Joan Bailey.\n",
    "\n",
    "> A story about a family of mice living in Brambly Hedge, a fictional village in the English countryside.\n",
    "\n",
    "> The product of Autumn Story Brambly Hedge is a book about a hedgehog named Mrs. Tiggy-Winkle. She is a very kind and friendly character who loves to help others. She also has a great sense of humor and enjoys telling jokes. She is a hardworking and dedicated person, who always puts others first. She is a great role model for children and adults alike. She is a wonderful character who has a great impact on the world around her. She is a true inspiration and a role model for all of us.\n",
    "\n",
    "> Autumn Story Brambly Hedge is a book that tells the story of a family of hedgehogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c261d3",
   "metadata": {},
   "source": [
    "## 4. Fine Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3542c894",
   "metadata": {},
   "source": [
    "Definindo a função que mapeará os textos de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(data_file):\n",
    "    inputs       = data_file[\"title\"]\n",
    "    responses      = data_file[\"content\"]\n",
    "    texts = []\n",
    "    for input, response in zip(inputs, responses):\n",
    "        text = prompt.format(input, response) + tokenizer.eos_token\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb44ddf",
   "metadata": {},
   "source": [
    "Carregamos o dataset tratado anteriormentre (passo 2) e remapeamos ele para ficar do jeitinho que precisamos para o Fine Tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0df0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files=AMAZON_TITLES_TRATADOS_PATH, split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "\n",
    "for item in dataset.select(range(5)):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199de09",
   "metadata": {},
   "source": [
    "Configurando o model para fazermos Fine Tunning do modo mais eficiente possível. Aqui estamos usando diversos valores padronizados, como explicado em aula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2c9f8",
   "metadata": {},
   "source": [
    "Configurando o Processo de Treinamento com os hyperparâmetros necessários. Novamente, aqui a maioria dos valores está de forma padronizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95de8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = MAX_SEQ_LENGTH,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d0222",
   "metadata": {},
   "source": [
    "Fazemos o treino efetivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d62d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08ff848",
   "metadata": {},
   "source": [
    "Salvamos o modelo para que possamos resusá-lo em outro momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/drive/MyDrive/Estudo/lora_model\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/Estudo/lora_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b525f",
   "metadata": {},
   "source": [
    "## 5. Testes após Tuniing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt.format(\n",
    "        \"Girls Ballet Tutu Neon Pink\",\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce89b5",
   "metadata": {},
   "source": [
    "> This is a beautiful tutu in a vibrant pink color. It has a 2 inch satin waistband and a 5 inch skirt. The tutu is made of nylon spandex. It is a size 3/4 and fits a child from 2 to 5 years old.\n",
    "\n",
    "> Neon pink tutu is a fun and flirty tutu for any little ballerina. It is made of tulle and has a layer of tulle on the bottom. The tutu is 20 inches long and is made to fit a 2T-4T child.\n",
    "\n",
    "> This tutu is a perfect addition to your little girl's ballet costume.\n",
    "\n",
    "> Tutu is made of high quality tulle. It has an elastic waistband with a bow and a ruffle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8224550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt.format(\n",
    "        \"Autumn Story Brambly Hedge\",\n",
    "        \"\",\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174c2471",
   "metadata": {},
   "source": [
    "> A wonderful story of adventure, excitement and romance. Autumn is here and the Brambly Hedge residents are getting ready for the harvest. But when Poppy's little brother, Parsley, gets lost in the woods, she must find him before the snow falls and winter comes. This is a story of adventure, excitement and romance.\n",
    "\n",
    "> The first book in the Brambly Hedge series, which has sold over 1.5 million copies worldwide.\n",
    "\n",
    "> A charming collection of stories about the adventures of a group of mice living in a hedge. The stories are set in the changing seasons and feature beautiful illustrations of the animals and their surroundings.\n",
    "\n",
    "> Brambly Hedge is the story of the adventures of a group of mice who live in a bramble patch, in a hollow tree. The mice live together in harmony, with the seasons, and with each other. Autumn Story is the second book in the series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78481030",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "- O fine-tuning permitiu que o modelo aprendesse a gerar descrições de produtos no estilo do dataset AmazonTitles.\n",
    "\n",
    "- Antes do fine-tuning, as descrições eram genéricas; depois, tornaram-se mais precisas e detalhadas, demonstrando a eficácia do processo.\n",
    "\n",
    "# Destaques:\n",
    "\n",
    "- O uso da Unsloth acelerou o treinamento.\n",
    "\n",
    "- A técnica LoRA permitiu ajustar o modelo com poucos parâmetros treináveis (0,52% do total).\n",
    "\n",
    "- O modelo após o fine-tuning gera descrições que refletem o estilo e o conteúdo do dataset.\n",
    "\n",
    "**Observação**: O exemplo mostrou uma melhora nas descrições, tornando-as mais específicas e adequadas ao contexto de produtos da Amazon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
