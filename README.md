# üéØ Fine Tuning para Descri√ß√£o de Produtos
Tech Chalenge 3:
Projeto de P√≥s-Gradua√ß√£o da FIAP ‚Äî Disciplina de OpenAI

# Vis√£o geral

Este reposit√≥rio demonstra um fluxo completo de fine-tuning de um foundation model para responder perguntas sobre t√≠tulos de produtos, retornando descri√ß√µes aprendidas a partir do dataset AmazonTitles-1.3MM (colunas title e content). O projeto segue as etapas pedidas no enunciado do Tech Challenge: preparar o dataset, testar o modelo base, treinar (fine-tuning) e testar o modelo treinado com prompts de entrada.

# Estrutura

finetuning_summarizer.ipynb ‚Äî notebook com todo o pipeline:

1. Prepara√ß√£o do ambiente: imports, montagem do Google Drive e vari√°veis de ambiente.

2. Leitura e tratamento da base: leitura de trn.json, filtragem/limpeza e gera√ß√£o de trn_tratado.json contendo title e content.

3. Modelo base (pr√©-treino): carregamento via unsloth.FastLanguageModel e teste antes do fine-tuning.

4. Fine-tuning (SFT): formata√ß√£o de prompts, datasets.load_dataset do JSON tratado, trl.SFTTrainer + transformers.TrainingArguments.

5. Testes p√≥s-treino: gera√ß√£o com o modelo j√° ajustado (comparativo com a etapa 3).

# Requisitos

Python 3.10+
GPU com CUDA (ex.: Google Colab com T4/A100)
Bibliotecas principais:

unsloth (carregamento e acelera√ß√£o 4-bit)
transformers, trl, datasets, torch
(opcional) google.colab para montar o Drive

# Instala√ß√£o (exemplo Colab)
pip install -q unsloth transformers trl datasets accelerate bitsandbytes

# Dataset

Fonte: AmazonTitles-1.3MM

Arquivo: trn.json (usar colunas title e content)

Tratamento: o notebook filtra registros com content v√°lido e salva trn_tratado.json com { "title": ..., "content": ... }.

# Modelo e Prompt

Modelo base: unsloth/llama-3-8b-bnb-4bit (carregado via FastLanguageModel.from_pretrained em 4-bit).

Prompt de instru√ß√£o (resumo do notebook):

Instru√ß√£o: ‚ÄúDescreva o produto de [INPUT]‚Äù

Input: recebe o t√≠tulo (title)

Response: esperado o texto de descri√ß√£o (content)

Gera√ß√£o de teste: uso de TextStreamer e model.generate(...) antes e depois do treinamento.

# Fine-Tuning (SFT)

Formata√ß√£o: fun√ß√£o formatting_prompts_func concatena instru√ß√£o + entrada (title) + r√≥tulo (content) + eos_token.

Dataset: datasets.load_dataset("json", data_files=AMAZON_TITLES_TRATADOS_PATH, split="train") + .map(...).

Trainer: trl.SFTTrainer(model=..., tokenizer=..., dataset_text_field="text", ...).

TrainingArguments (principais, do notebook):

per_device_train_batch_size = 2

gradient_accumulation_steps = 4

warmup_steps = 5

max_steps = 60

learning_rate = 2e-4

fp16/bf16 conforme suporte (is_bfloat16_supported())

optim = "adamw_8bit"

weight_decay = 0.01

lr_scheduler_type = "linear"

seed = 3407

output_dir = "outputs"

# Como rodar

1. Abra o notebook finetuning_summarizer.ipynb no Google Colab.

2. Monte seu Google Drive (c√©lula j√° inclu√≠da) e ajuste:

  AMAZON_TITLES_PATH (caminho para trn.json)
  
  AMAZON_TITLES_TRATADOS_PATH (onde salvar trn_tratado.json)

3. Execute as c√©lulas em ordem:

  Prepara√ß√£o do ambiente e imports
  
  Leitura/tratamento do dataset
  
  Teste do modelo base
  
  Fine-tuning (trainer.train())
  
  Teste p√≥s-treino (comparar com o pr√©-treino)

4. Os artefatos de treino ser√£o salvos em outputs/ (padr√£o do TrainingArguments.output_dir).
